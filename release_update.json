{
  "body": "# First Block Cache Development Details\r\n\r\n## Overview\r\n\r\nThis document provides a complete detailed explanation of the development of the First Block Cache feature for Nunchaku SDXL models, including created files, modified files, code, and their meanings.\r\n\r\n## Created and Modified Files\r\n\r\n1. `FirstBlockCachePatchNode.py` - Newly created (main node implementation)\r\n2. `patch_util.py` - Newly created (utility functions)\r\n3. `__init__.py` - Modified (node registration)\r\n\r\n---\r\n\r\n## 1. FirstBlockCachePatchNode.py (Main Node Implementation)\r\n\r\n### File Purpose\r\n\r\nA ComfyUI node that implements the First Block Cache feature exclusively for Nunchaku SDXL models. It caches the output of the first Transformer block and skips recalculation when similar, achieving speedup.\r\n\r\n### Key Constants and Variables\r\n\r\n#### `fb_cache_key_attrs = \"fb_cache_attr\"`\r\n\r\nThe key name for storing cache attributes in `transformer_options`. Used to store cache state in ComfyUI's `transformer_options` dictionary.\r\n\r\n#### `fb_cache_model_temp = \"nunchaku_fb_cache\"`\r\n\r\nThe attribute name for storing cache attributes directly on the `diffusion_model` object. Used to persist cache state on the model instance.\r\n\r\n### Key Function Explanations\r\n\r\n#### `are_two_tensors_similar` Function (lines 51-57)\r\n\r\nA function that determines whether two tensors are similar.\r\n\r\n```python\r\ndef are_two_tensors_similar(t1, t2, *, threshold):\r\n    if t1.shape != t2.shape:\r\n        return False\r\n    mean_diff = (t1 - t2).abs().mean()\r\n    mean_t1 = t1.abs().mean()\r\n    diff = mean_diff / mean_t1\r\n    return diff.item() < threshold\r\n```\r\n\r\n**Meaning:**\r\n- Returns `False` if shapes differ\r\n- Calculates the mean absolute error between two tensors\r\n- Normalizes by the mean absolute value of the original tensor\r\n- Determines similarity if normalized error is below `threshold`\r\n\r\n**Usage Example:**\r\nWith `residual_diff_threshold=0.2`, a normalized error below 20% is considered a cache hit.\r\n\r\n#### `_patch_unet_for_cache` Function (lines 59-108)\r\n\r\nA function that patches the UNet model's `forward` method and `transformer_blocks`.\r\n\r\n**Processing Flow:**\r\n\r\n1. **Wrap UNet's forward method (lines 68-101)**\r\n   - Extract `step_i` from `timestep` and save to cache context\r\n   - Initialize `cache_stats` (if not present)\r\n   - Call original `forward`\r\n\r\n**Important Point:**\r\n```python\r\ncache_attrs['step_i'] = step_i\r\n```\r\nRecords the current timestep at each step. For multi-stage samplers like HeunPP2, this is called multiple times with the same `step_i`, so we detect this and invalidate the cache.\r\n\r\n2. **Patch transformer_blocks (line 108)**\r\n   - Calls `_patch_unet_transformer_blocks_for_cache`\r\n\r\n#### `_patch_unet_transformer_blocks_for_cache` Function (lines 110-283)\r\n\r\nA function that patches individual `transformer_blocks` within the UNet.\r\n\r\n**Processing Flow:**\r\n\r\n1. **Identify the first transformer_block (lines 228-240)**\r\n```python\r\nfor block_idx, down_block in enumerate(unet_model.down_blocks):\r\n    if hasattr(down_block, 'attentions') and len(down_block.attentions) > 0:\r\n        first_attn = down_block.attentions[0]\r\n        if isinstance(first_attn, Transformer2DModel) and hasattr(first_attn, 'transformer_blocks'):\r\n            if len(first_attn.transformer_blocks) > 0:\r\n                first_tb = first_attn.transformer_blocks[0]\r\n                if _patch_transformer_block(first_tb, is_first_block=True):\r\n```\r\n\r\nIdentifies the first `transformer_block` of the first `attention` of the first `down_block` and patches it with `is_first_block=True`.\r\n\r\n**Meaning:**\r\n- Only the first block is cached\r\n- If the first block's output is similar, subsequent blocks can skip calculation\r\n\r\n2. **First block patch (lines 122-223, within `_patch_transformer_block`)**\r\n\r\n**`cached_forward` Function Behavior (lines 128-217):**\r\n\r\n**Step 1: Sampler Detection (lines 136-138)**\r\n```python\r\nif cache_attrs.get(\"fb_cache_disable_for_sampler\", False):\r\n    cache_attrs[\"should_calc\"] = True\r\n    return original_forward(hidden_states, *args, **kwargs)\r\n```\r\nFor multi-stage samplers like HeunPP2/Heun, completely disables the cache.\r\n\r\n**Step 2: Timestep Range Check (lines 140-148)**\r\n```python\r\nin_step = timestep_end <= step_i <= timestep_start\r\nif not in_step:\r\n    return original_forward(hidden_states, *args, **kwargs)\r\n```\r\nDisables cache outside the range specified by `start_at`/`end_at`.\r\n\r\n**Step 3: First Block Cache Processing (lines 153-209)**\r\n\r\n**Duplicate Timestep Detection (lines 156-167)**\r\n```python\r\nlast_step_i = cache_attrs.get('fb_cache_last_step_i')\r\nif last_step_i is not None and step_i == last_step_i:\r\n    # Force calculation\r\n    cache_attrs['should_calc'] = True\r\n    output = original_forward(hidden_states, *args, **kwargs)\r\n    return output\r\n```\r\nForces calculation when the same `step_i` is called consecutively. For multi-stage samplers like HeunPP2, this prevents cache interference that would corrupt images.\r\n\r\n**Similarity Check (lines 169-203)**\r\n```python\r\ncalc_start = time.time()\r\noutput = original_forward(hidden_states, *args, **kwargs)\r\ncalc_time = time.time() - calc_start\r\n\r\nprevious_first_block_residual = cache_attrs.get('previous_first_block_residual')\r\nif previous_first_block_residual is not None:\r\n    should_calc = not are_two_tensors_similar(\r\n        previous_first_block_residual,\r\n        output,\r\n        threshold=cache_attrs.get('rel_diff_threshold', residual_diff_threshold)\r\n    )\r\n```\r\n- Always executes calculation\r\n- Compares with previous output\r\n- Cache hit if similar, miss otherwise\r\n\r\n**Cache Hit Processing (lines 187-191)**\r\n```python\r\nif not should_calc:\r\n    stats['cache_hits'] = stats.get('cache_hits', 0) + 1\r\n    stats['first_block_cache_count'] = stats.get('first_block_cache_count', 0) + 1\r\n    logger.info(f\"[FB Cache] Step {step_i:.2f}: CACHE HIT ...\")\r\n```\r\nUpdates statistics and outputs logs. Subsequent blocks skip calculation due to `should_calc=False`.\r\n\r\n**Cache Miss Processing (lines 193-203)**\r\n```python\r\nelse:\r\n    stats['cache_misses'] = stats.get('cache_misses', 0) + 1\r\n    cache_attrs['previous_first_block_residual'] = output.clone()\r\n```\r\nUpdates statistics and saves current output. Subsequent blocks calculate with `should_calc=True`.\r\n\r\n**Step 4: Subsequent Block Processing (lines 210-217)**\r\n```python\r\nelse:\r\n    should_calc = cache_attrs.get('should_calc', True)\r\n    if should_calc:\r\n        return original_forward(hidden_states, *args, **kwargs)\r\n    else:\r\n        return hidden_states\r\n```\r\nIf the first block had a cache hit, `should_calc=False`, and subsequent blocks skip calculation and return input as-is.\r\n\r\n#### `fb_cache_prepare_wrapper` Function (lines 407-527)\r\n\r\nA wrapper function that initializes the cache before and after sampling execution and outputs statistics.\r\n\r\n**Processing Flow:**\r\n\r\n1. **Sampler Detection (lines 414-459)**\r\n```python\r\nsampler_name_l = (str(sampler_name) if sampler_name is not None else \"\").lower()\r\ndisable_cache_for_sampler = (\r\n    (\"heunpp2\" in sampler_name_l) or (\"heun++\" in sampler_name_l) or \r\n    (\"heunpp\" in sampler_name_l) or (\"heun\" in sampler_name_l) or ...\r\n)\r\n```\r\nDetects Heun-family samplers and sets the `fb_cache_disable_for_sampler` flag.\r\n\r\n**Meaning:**\r\n- HeunPP2/Heun++/HeunPP/Heun are multi-stage samplers\r\n- They call the model multiple times at the same timestep\r\n- Cache interference would corrupt images, so cache is disabled entirely\r\n\r\n2. **Cache Attribute Initialization (lines 462-466)**\r\n```python\r\nif not hasattr(diffusion_model, fb_cache_model_temp):\r\n    setattr(diffusion_model, fb_cache_model_temp, {})\r\ncache_attrs = getattr(diffusion_model, fb_cache_model_temp, {})\r\ncache_attrs[\"fb_cache_disable_for_sampler\"] = bool(disable_cache_for_sampler)\r\n```\r\nSets cache attributes on `diffusion_model`. This allows patched blocks to reference them.\r\n\r\n3. **Sampling Execution (lines 473-475)**\r\n```python\r\nout = wrapper_executor(noise, latent_image, sampler, sigmas, ...)\r\n```\r\n\r\n4. **Statistics Output (lines 476-522)**\r\n```python\r\ncache_stats = cache_attrs.get('cache_stats', {})\r\nif cache_stats:\r\n    total_steps = cache_stats.get('total_steps', 0)\r\n    cache_hits = cache_stats.get('cache_hits', 0)\r\n    cache_misses = cache_stats.get('cache_misses', 0)\r\n    hit_rate = (cache_hits / (cache_hits + cache_misses)) * 100\r\n    estimated_speedup = 1.0 + (hit_rate / 100.0) * 0.15\r\n```\r\nAggregates cache statistics and outputs hit rate and estimated speedup to logs.\r\n\r\n#### `NunchakuUssoewwinApplyFirstBlockCachePatchAdvanced` Class (lines 529-626)\r\n\r\nThe ComfyUI node implementation class.\r\n\r\n**`INPUT_TYPES` (lines 532-561)**\r\n```python\r\n\"residual_diff_threshold\": (\"FLOAT\", {\r\n    \"default\": 0.00,\r\n    \"min\": 0.0,\r\n    \"max\": 1.0,\r\n    \"step\": 0.01,\r\n    \"tooltip\": \"Nunchaku SDXL: 0 (original), 0.12 (1.8x speedup).\"\r\n})\r\n```\r\n\r\n**Meaning:**\r\n- `0.0`: Cache disabled (always calculates)\r\n- `0.12` (SDXL): Approximately 1.8x speedup\r\n\r\n**`apply_patch_advanced` Function (lines 571-625)**\r\n\r\n**Processing Flow:**\r\n\r\n1. **Model Clone (line 573)**\r\n```python\r\nmodel = model.clone()\r\n```\r\nApplies patch to clone without modifying the original model.\r\n\r\n2. **Existing Patch Check (lines 575-577)**\r\n```python\r\nif residual_diff_threshold == 0 or len(model.get_wrappers(...)) > 0:\r\n    return (model,)\r\n```\r\nSkips if `threshold=0` or already patched.\r\n\r\n3. **Nunchaku Model Validation (lines 579-582)**\r\n```python\r\ndiffusion_model = model.get_model_object('diffusion_model')\r\nif not is_nunchaku_model(diffusion_model):\r\n    logger.warning(\"First Block Cache patch is not applied because the model is not a Nunchaku model.\")\r\n    return (model,)\r\n```\r\n\r\n4. **Timestep Range Calculation (lines 586-598)**\r\n```python\r\nsigma_start = model_sampling.percent_to_sigma(start_at)\r\nsigma_end = model_sampling.percent_to_sigma(end_at)\r\nif not isinstance(sigma_start, torch.Tensor):\r\n    sigma_start = torch.tensor(sigma_start, dtype=torch.float32)\r\nfb_cache_attrs['timestep_start'] = model_sampling.timestep(sigma_start)\r\nfb_cache_attrs['timestep_end'] = model_sampling.timestep(sigma_end)\r\n```\r\nConverts `start_at`/`end_at` (0.0-1.0) to sigma, then to timestep. Since `percent_to_sigma` may return `float`, conversion to `torch.Tensor` is necessary.\r\n\r\n5. **Model Type-Specific Patch Application (lines 600-616)**\r\n\r\n**SDXL (UNet-based) Case (lines 611-614)**\r\n```python\r\nelif is_nunchaku_sdxl_model(diffusion_model):\r\n    _patch_unet_for_cache(diffusion_model, fb_cache_attrs, residual_diff_threshold)\r\n```\r\nDirectly patches UNet's `forward` and `transformer_blocks`.\r\n\r\n6. **Wrapper Addition (lines 619-623)**\r\n```python\r\nmodel.add_wrapper_with_key(\r\n    comfy.patcher_extension.WrappersMP.OUTER_SAMPLE,\r\n    patch_key,\r\n    fb_cache_prepare_wrapper\r\n)\r\n```\r\nRegisters `fb_cache_prepare_wrapper` as an `OUTER_SAMPLE` wrapper. Called during sampling execution.\r\n\r\n---\r\n\r\n## 2. patch_util.py (Utility Functions)\r\n\r\n### File Purpose\r\n\r\nProvides utility functions for model patch application and Nunchaku model detection.\r\n\r\n### `PatchKeys` Class (lines 4-21)\r\n\r\nA class that defines patch keys within `transformer_options`.\r\n\r\n```python\r\ndit_enter = \"patch_dit_enter\"\r\ndit_double_block_with_control_replace = \"patch_dit_double_block_with_control_replace\"\r\ndit_exit = \"patch_dit_exit\"\r\n```\r\n\r\nDiT model patch points. Used in ComfyUI's `transformer_options`.\r\n\r\n### `set_model_patch` Function (lines 24-28)\r\n\r\nA function that adds patch functions to `transformer_options` (appends to list).\r\n\r\n```python\r\nto[options_key][name] = to[options_key].get(name, []) + [patch]\r\n```\r\n\r\nAllows registering multiple patches to the same key.\r\n\r\n### `set_model_patch_replace` Function (lines 30-34)\r\n\r\nA function that sets patch functions in `transformer_options` (replaces).\r\n\r\n```python\r\nto[options_key][name] = patch\r\n```\r\n\r\nReplaces existing patches.\r\n\r\n### `add_model_patch_option` Function (lines 36-42)\r\n\r\nA function that adds a dictionary for patches to `transformer_options`.\r\n\r\n```python\r\nif patch_key not in to:\r\n    to[patch_key] = {}\r\nreturn to[patch_key]\r\n```\r\n\r\nEnsures a dictionary for storing cache attributes.\r\n\r\n### `is_nunchaku_sdxl_model` Function (lines 57-65)\r\n\r\nA function that determines whether a model is a Nunchaku SDXL model.\r\n\r\n```python\r\nfrom nunchaku.models.unets.unet_sdxl import NunchakuSDXLUNet2DConditionModel\r\nif isinstance(model, NunchakuSDXLUNet2DConditionModel):\r\n    return True\r\n```\r\n\r\n### `is_nunchaku_model` Function (lines 77-79)\r\n\r\nA function that determines whether a model is a Nunchaku SDXL model.\r\n\r\n```python\r\nreturn is_nunchaku_sdxl_model(model)\r\n```\r\n\r\n---\r\n\r\n## 3. __init__.py (Node Registration)\r\n\r\n### Modified Section (lines 410-413)\r\n\r\n```python\r\ntry:\r\n    from .nodes.FirstBlockCachePatchNode import NunchakuUssoewwinApplyFirstBlockCachePatchAdvanced\r\n    NODE_CLASS_MAPPINGS[\"NunchakuUssoewwinApplyFirstBlockCachePatchAdvanced\"] = NunchakuUssoewwinApplyFirstBlockCachePatchAdvanced\r\nexcept (ImportError, ModuleNotFoundError) as e:\r\n    logger.exception(f\"Node `NunchakuUssoewwinApplyFirstBlockCachePatchAdvanced` import failed: {e}\")\r\n```\r\n\r\n**Meaning:**\r\n- Imports node class from `FirstBlockCachePatchNode.py`\r\n- Registers in `NODE_CLASS_MAPPINGS` for ComfyUI recognition\r\n- Outputs exception to log on import failure\r\n\r\n---\r\n\r\n## Technical Design Philosophy\r\n\r\n### 1. UNet-based Architecture\r\n\r\n#### SDXL (UNet-based)\r\n- Structure with `down_blocks`, `mid_block`, `up_blocks`\r\n- Each block contains `Transformer2DModel`\r\n- Directly patches `forward` method\r\n- Individually patches `transformer_blocks`' `forward`\r\n\r\n### 2. Cache Operation Principle\r\n\r\n#### First Block Cache Concept\r\n1. Save output of first Transformer block\r\n2. Check similarity at next step\r\n3. Skip subsequent block calculation if similar\r\n4. Calculate all blocks if not similar\r\n\r\n#### Why Only the First Block\r\n- If the first block's output is similar, subsequent blocks are likely similar too\r\n- Comparing only the first block is efficient\r\n- Comparing all blocks has large overhead\r\n\r\n### 3. Multi-stage Sampler Support\r\n\r\n#### Problem\r\n- Multi-stage samplers like HeunPP2 call the model multiple times at the same timestep\r\n- Cache interference would corrupt images\r\n\r\n#### Solution\r\n1. Detect by sampler name (`fb_cache_prepare_wrapper`)\r\n2. Set `fb_cache_disable_for_sampler` flag\r\n3. Check flag in patched blocks and disable cache\r\n\r\n### 4. Statistics and Logging\r\n\r\n#### `cache_stats` Dictionary Items\r\n- `total_steps`: Total number of steps\r\n- `cache_hits`: Number of cache hits\r\n- `cache_misses`: Number of cache misses\r\n- `steps_in_range`: Number of steps within range\r\n- `steps_out_range`: Number of steps outside range\r\n- `first_block_calc_count`: Number of first block calculations\r\n- `first_block_cache_count`: Number of first block cache uses\r\n- `start_time`: Start time\r\n\r\n#### Estimated Speedup Calculation (line 517)\r\n```python\r\nestimated_speedup = 1.0 + (hit_rate / 100.0) * 0.15\r\n```\r\n\r\n- Simple estimation based on hit rate\r\n- Assumes first block is approximately 15% of total\r\n- 50% hit rate yields approximately 1.075x speedup\r\n\r\n---\r\n\r\n## Summary\r\n\r\nThis implementation enables First Block Cache for Nunchaku SDXL models, achieving approximately 1.08-1.8x speedup with Euler samplers. For multi-stage samplers like HeunPP2/Heun, the cache is automatically disabled to maintain quality.\r\n\r\n"
}
